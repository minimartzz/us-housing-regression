{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Date | User | Change Type | Remarks |  \n",
    "| ---- | ---- | ----------- | ------- |\n",
    "| 30/10/2025   | Martin | Create  | Creating an ML dashboard for housing price prediction | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Content\n",
    "\n",
    "* [Load Data](#load-data)\n",
    "* [Split Data](#data-split)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/raw/HouseTS.csv\")\n",
    "metros = pd.read_csv(\"../data/raw/usmetros.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>median_sale_price</th>\n",
       "      <th>median_list_price</th>\n",
       "      <th>median_ppsf</th>\n",
       "      <th>median_list_ppsf</th>\n",
       "      <th>homes_sold</th>\n",
       "      <th>pending_sales</th>\n",
       "      <th>new_listings</th>\n",
       "      <th>inventory</th>\n",
       "      <th>median_dom</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Housing Units</th>\n",
       "      <th>Median Rent</th>\n",
       "      <th>Median Home Value</th>\n",
       "      <th>Total Labor Force</th>\n",
       "      <th>Unemployed Population</th>\n",
       "      <th>Total School Age Population</th>\n",
       "      <th>Total School Enrollment</th>\n",
       "      <th>Median Commute Time</th>\n",
       "      <th>price</th>\n",
       "      <th>city_full</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-31</td>\n",
       "      <td>46550.0</td>\n",
       "      <td>217450.0</td>\n",
       "      <td>31.813674</td>\n",
       "      <td>110.183666</td>\n",
       "      <td>14.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>59.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>279500.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>200773.999557</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-30</td>\n",
       "      <td>61870.0</td>\n",
       "      <td>245000.0</td>\n",
       "      <td>40.723982</td>\n",
       "      <td>130.528256</td>\n",
       "      <td>22.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>89.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>279500.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>202421.064584</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-05-31</td>\n",
       "      <td>125500.0</td>\n",
       "      <td>217450.0</td>\n",
       "      <td>63.913043</td>\n",
       "      <td>119.919216</td>\n",
       "      <td>24.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>144.5</td>\n",
       "      <td>...</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>279500.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>202681.309539</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-06-30</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>189900.0</td>\n",
       "      <td>81.598080</td>\n",
       "      <td>105.617353</td>\n",
       "      <td>34.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>279500.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>202998.603897</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-07-31</td>\n",
       "      <td>165500.0</td>\n",
       "      <td>154000.0</td>\n",
       "      <td>81.598080</td>\n",
       "      <td>83.921175</td>\n",
       "      <td>39.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2677.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>279500.0</td>\n",
       "      <td>3171.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>5408.0</td>\n",
       "      <td>2492.0</td>\n",
       "      <td>203781.903446</td>\n",
       "      <td>Atlanta-Sandy Springs-Alpharetta</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  median_sale_price  median_list_price  median_ppsf  \\\n",
       "0  2012-03-31            46550.0           217450.0    31.813674   \n",
       "1  2012-04-30            61870.0           245000.0    40.723982   \n",
       "2  2012-05-31           125500.0           217450.0    63.913043   \n",
       "3  2012-06-30           153000.0           189900.0    81.598080   \n",
       "4  2012-07-31           165500.0           154000.0    81.598080   \n",
       "\n",
       "   median_list_ppsf  homes_sold  pending_sales  new_listings  inventory  \\\n",
       "0        110.183666        14.0           23.0          44.0       64.0   \n",
       "1        130.528256        22.0           29.0          56.0       69.0   \n",
       "2        119.919216        24.0           40.0          63.0       60.0   \n",
       "3        105.617353        34.0           46.0          50.0       57.0   \n",
       "4         83.921175        39.0           49.0          42.0       50.0   \n",
       "\n",
       "   median_dom  ...  Total Housing Units  Median Rent  Median Home Value  \\\n",
       "0        59.5  ...               2677.0        710.0           279500.0   \n",
       "1        89.5  ...               2677.0        710.0           279500.0   \n",
       "2       144.5  ...               2677.0        710.0           279500.0   \n",
       "3       126.0  ...               2677.0        710.0           279500.0   \n",
       "4        80.0  ...               2677.0        710.0           279500.0   \n",
       "\n",
       "  Total Labor Force  Unemployed Population  Total School Age Population  \\\n",
       "0            3171.0                  460.0                       5408.0   \n",
       "1            3171.0                  460.0                       5408.0   \n",
       "2            3171.0                  460.0                       5408.0   \n",
       "3            3171.0                  460.0                       5408.0   \n",
       "4            3171.0                  460.0                       5408.0   \n",
       "\n",
       "   Total School Enrollment  Median Commute Time          price  \\\n",
       "0                   5408.0               2492.0  200773.999557   \n",
       "1                   5408.0               2492.0  202421.064584   \n",
       "2                   5408.0               2492.0  202681.309539   \n",
       "3                   5408.0               2492.0  202998.603897   \n",
       "4                   5408.0               2492.0  203781.903446   \n",
       "\n",
       "                          city_full  \n",
       "0  Atlanta-Sandy Springs-Alpharetta  \n",
       "1  Atlanta-Sandy Springs-Alpharetta  \n",
       "2  Atlanta-Sandy Springs-Alpharetta  \n",
       "3  Atlanta-Sandy Springs-Alpharetta  \n",
       "4  Atlanta-Sandy Springs-Alpharetta  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date\n",
      "2013    74712\n",
      "2014    74712\n",
      "2015    74712\n",
      "2016    74712\n",
      "2017    74712\n",
      "2018    74712\n",
      "2019    74712\n",
      "2020    74712\n",
      "2021    74712\n",
      "2022    74712\n",
      "2023    74712\n",
      "2012    62260\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])\n",
    "print(df['date'].dt.year.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split\n",
    "\n",
    "- Training data (2012-2019)\n",
    "- Validation data (2020-2021)\n",
    "- Testing data (2022-2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (585244, 39)\n",
      "Validation data shape: (149424, 39)\n",
      "Testing data shape: (149424, 39)\n"
     ]
    }
   ],
   "source": [
    "# Sort by date\n",
    "df = df.sort_values(\"date\")\n",
    "\n",
    "# Define cutoff dates\n",
    "cutoff_date_train = \"2019-12-31\"\n",
    "cutoff_date_validation = \"2021-12-31\"\n",
    "\n",
    "# Train data\n",
    "train_df = df[df['date'] <= cutoff_date_train]\n",
    "valid_df = df[(df['date'] > cutoff_date_train) & (df['date'] <= cutoff_date_validation)]\n",
    "test_df = df[df['date'] > cutoff_date_validation]\n",
    "\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Validation data shape: {valid_df.shape}\")\n",
    "print(f\"Testing data shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.to_csv(\"../data/raw/train.csv\", index=False)\n",
    "# test_df.to_csv(\"../data/raw/test.csv\", index=False)\n",
    "# valid_df.to_csv(\"../data/raw/valid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replacing `city_full` with latitude and longitude information, since there are too many to count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city_full\n",
       "New York-Newark-Jersey City            78020\n",
       "Chicago-Naperville-Elgin               35344\n",
       "Los Angeles-Long Beach-Anaheim         33840\n",
       "Philadelphia-Camden-Wilmington         31396\n",
       "DC_Metro                               29516\n",
       "Pittsburgh                             27824\n",
       "Boston-Cambridge-Newton                25568\n",
       "Dallas-Fort Worth-Arlington            23594\n",
       "Houston-The Woodlands-Sugar Land       20586\n",
       "Minneapolis-St. Paul-Bloomington       20398\n",
       "Detroit-Warren-Dearborn                20022\n",
       "St. Louis                              19834\n",
       "Atlanta-Sandy Springs-Alpharetta       19082\n",
       "Miami-Fort Lauderdale-Pompano Beach    17014\n",
       "San Francisco-Oakland-Berkeley         15604\n",
       "Seattle-Tacoma-Bellevue                14664\n",
       "Phoenix-Mesa-Chandler                  14006\n",
       "Cincinnati                             14006\n",
       "Baltimore-Columbia-Towson              13818\n",
       "Riverside-San Bernardino-Ontario       13724\n",
       "Tampa-St. Petersburg-Clearwater        12126\n",
       "Denver-Aurora-Lakewood                 11750\n",
       "Portland-Vancouver-Hillsboro           11092\n",
       "Sacramento-Roseville-Folsom            10716\n",
       "Charlotte-Concord-Gastonia              9870\n",
       "San Antonio-New Braunfels               9776\n",
       "San Diego-Chula Vista-Carlsbad          8930\n",
       "Orlando-Kissimmee-Sanford               8554\n",
       "Austin-Round Rock-Georgetown            8084\n",
       "Las Vegas-Henderson-Paradise            6486\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['city_full'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remap some city names\n",
    "city_mapping = {\n",
    "  'Las Vegas-Henderson-Paradise': 'Las Vegas-Henderson-North Las Vegas',\n",
    "  'Denver-Aurora-Lakewood': 'Denver-Aurora-Centennial',\n",
    "  'Houston-The Woodlands-Sugar Land': 'Houston-Pasadena-The Woodlands',\n",
    "  'Austin-Round Rock-Georgetown': 'Austin-Round Rock-San Marcos',\n",
    "  'Miami-Fort Lauderdale-Pompano Beach': 'Miami-Fort Lauderdale-West Palm Beach',\n",
    "  'San Francisco-Oakland-Berkeley': 'San Francisco-Oakland-Fremont',\n",
    "  'DC_Metro': 'Washington-Arlington-Alexandria',\n",
    "  'Atlanta-Sandy Springs-Alpharetta': 'Atlanta-Sandy Springs-Roswell'\n",
    "}\n",
    "\n",
    "def clean_and_merge(df: pd.DataFrame) -> pd.DataFrame:\n",
    "  \"\"\"Apply city name fixes, merge lat/lng from metros, drop dup col.\"\"\"\n",
    "  df[\"city_full\"] = df[\"city_full\"].replace(city_mapping)\n",
    "  \n",
    "  df = df.merge(\n",
    "    metros[[\"metro_full\", \"lat\", \"lng\"]],\n",
    "    how=\"left\",\n",
    "    left_on=\"city_full\",\n",
    "    right_on=\"metro_full\"\n",
    "  )\n",
    "  df.drop(columns=[\"metro_full\"], inplace=True)\n",
    "\n",
    "  # Log any cities that still didn’t match\n",
    "  missing = df[df[\"lat\"].isnull()][\"city_full\"].unique()\n",
    "  if len(missing) > 0:\n",
    "    print(\"⚠️ Still missing lat/lng for:\", missing)\n",
    "  else:\n",
    "    print(\"✅ All cities matched with metros dataset.\")\n",
    "\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ All cities matched with metros dataset.\n",
      "✅ All cities matched with metros dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20240\\636688607.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"city_full\"] = df[\"city_full\"].replace(city_mapping)\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_20240\\636688607.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"city_full\"] = df[\"city_full\"].replace(city_mapping)\n"
     ]
    }
   ],
   "source": [
    "train_df = clean_and_merge(train_df)\n",
    "valid_df = clean_and_merge(valid_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check and remove duplicates\n",
    "\n",
    "- Some houses have their information shown on a later date, thus have multiple entries where the information is exactly the same less the date and year. So these are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(585244, 41)\n",
      "duplicated_rows: 0\n",
      "duplicated_rows excluding date column: 6321\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "\n",
    "duplicated_rows = train_df[train_df.duplicated()].shape[0]\n",
    "print(\"duplicated_rows:\", duplicated_rows)\n",
    "\n",
    "duplicated_rows = train_df[train_df.duplicated(subset=train_df.columns.difference(['date', 'year']))].shape[0]\n",
    "print(\"duplicated_rows excluding date column:\", duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(578923, 41)\n",
      "duplicated_rows: 0\n",
      "duplicated_rows excluding date column: 0\n"
     ]
    }
   ],
   "source": [
    "# Delete duplicates\n",
    "train_df = train_df.drop_duplicates(subset=train_df.columns.difference(['date', 'year']), keep='last')\n",
    "\n",
    "print(train_df.shape)\n",
    "\n",
    "duplicated_rows = train_df[train_df.duplicated()].shape[0]\n",
    "print(\"duplicated_rows:\", duplicated_rows)\n",
    "\n",
    "duplicated_rows = train_df[train_df.duplicated(subset=train_df.columns.difference(['date', 'year']))].shape[0]\n",
    "print(\"duplicated_rows excluding date column:\", duplicated_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: 2025-06-18T19:03:45.452311+08:00\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.9\n",
      "IPython version      : 8.31.0\n",
      "\n",
      "Compiler    : MSC v.1938 64 bit (AMD64)\n",
      "OS          : Windows\n",
      "Release     : 10\n",
      "Machine     : AMD64\n",
      "Processor   : Intel64 Family 6 Model 183 Stepping 1, GenuineIntel\n",
      "CPU cores   : 20\n",
      "Architecture: 64bit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%watermark"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
